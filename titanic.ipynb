{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-26T04:08:53.932852Z","iopub.execute_input":"2022-03-26T04:08:53.933615Z","iopub.status.idle":"2022-03-26T04:08:56.434938Z","shell.execute_reply.started":"2022-03-26T04:08:53.933514Z","shell.execute_reply":"2022-03-26T04:08:56.434134Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<h1>1. Importing dataset</h1>","metadata":{}},{"cell_type":"code","source":"X_train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n# train_data.head()\nX_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n# train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:56.436567Z","iopub.execute_input":"2022-03-26T04:08:56.437245Z","iopub.status.idle":"2022-03-26T04:08:56.462030Z","shell.execute_reply.started":"2022-03-26T04:08:56.437206Z","shell.execute_reply":"2022-03-26T04:08:56.461263Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<h1> 2. Checking the data </h1>","metadata":{}},{"cell_type":"markdown","source":"<h3> 2A) Checking Embarked </h3>","metadata":{}},{"cell_type":"code","source":"s1 = np.logical_and(X_train_data['Embarked'] == 'S' , X_train_data['Survived'] == 1).astype(int)\ns1 = sum(s1)\ns2 = np.logical_and(X_train_data['Embarked'] == 'C' , X_train_data['Survived'] == 1).astype(int)\ns2 = sum(s2)\ns3 = np.logical_and(X_train_data['Embarked'] == 'Q' , X_train_data['Survived'] == 1).astype(int)\ns3 = sum(s3)\n\nd1 = np.logical_and(X_train_data['Embarked'] == 'S' , X_train_data['Survived'] == 0).astype(int)\nd1 = sum(d1)\nd2 = np.logical_and(X_train_data['Embarked'] == 'C' , X_train_data['Survived'] == 0).astype(int)\nd2 = sum(d2)\nd3 = np.logical_and(X_train_data['Embarked'] == 'Q' , X_train_data['Survived'] == 0).astype(int)\nd3 = sum(d3)\na = torch.randn(10)\nb = a <= 0\nindices = b.nonzero()\n# width of the bars\nbarWidth = 0.3\n# Choose the height of the blue bars\n# bars1 = [10, 9, 2]\nbars1 = [s1,s2,s3]\n# Choose the height of the cyan bars\nbars2 = [d1,d2,d3]\n# The x position of bars\nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\n# Create blue bars\nplt.bar(r1, bars1, width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Survived')\n# Create cyan bars\nplt.bar(r2, bars2, width = barWidth, color = 'cyan', edgecolor = 'black',  capsize=7, label='Deceased')\n# general layout\nplt.xticks([r + barWidth for r in range(len(bars1))], ['S', 'C', 'Q'])\nplt.ylabel('Total')\nplt.xlabel('Port of Embarkation')\nplt.title('Embarked')\nplt.legend()\n# Show graphic\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:56.464394Z","iopub.execute_input":"2022-03-26T04:08:56.464876Z","iopub.status.idle":"2022-03-26T04:08:56.725877Z","shell.execute_reply.started":"2022-03-26T04:08:56.464836Z","shell.execute_reply":"2022-03-26T04:08:56.725222Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<h3> 2B) Cheking the Parch </h3>","metadata":{}},{"cell_type":"code","source":"max_parch_n = X_train_data['Parch'].max()\nprint(max_parch_n)\npNS = [None] * max_parch_n\nfor i in range(0, max_parch_n):\n    pNS[i] = np.logical_and(X_train_data['Parch'] == i , X_train_data['Survived'] == 1).astype(int)\n    pNS[i] = sum(pNS[i])\n# print(pNS)\npnD = [None] * max_parch_n\nfor i in range(0, max_parch_n):\n    pnD[i] = np.logical_and(X_train_data['Parch'] == i , X_train_data['Survived'] == 0).astype(int)\n    pnD[i] = sum(pnD[i])\na = torch.randn(10)\nb = a <= 0\nindices = b.nonzero()\n# width of the bars\nbarWidth = 0.3\n# Choose the height of the blue bars\n# bars1 = [10, 9, 2]\nbars1 = pNS\n# Choose the height of the cyan bars\nbars2 = pnD\n# The x position of bars\nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\n# Create blue bars\nplt.bar(r1, bars1, width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Survived')\n# Create cyan bars\nplt.bar(r2, bars2, width = barWidth, color = 'cyan', edgecolor = 'black',  capsize=7, label='Deceased')\n# general layout\nplt.xticks([r + barWidth for r in range(len(bars1))], ['Alone', '1', '2', '3', '4',  '5'])\nplt.xlabel('number of parents / children aboard')\nplt.ylabel('Total')\nplt.title('Parch')\nplt.legend()\n# Show graphic\nplt.show()\nmodParctch = (X_train_data['Parch'] >= 1)\n# print(modParctch.astype(int))\nX_train_data['Parch'] = modParctch.astype(int)\n#Saying that is like to say that all persons with 1+ is 50% 50% to survive","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:56.727881Z","iopub.execute_input":"2022-03-26T04:08:56.728426Z","iopub.status.idle":"2022-03-26T04:08:56.941689Z","shell.execute_reply.started":"2022-03-26T04:08:56.728367Z","shell.execute_reply":"2022-03-26T04:08:56.940967Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<h3> 2C) Cheking the Class </h3>","metadata":{}},{"cell_type":"code","source":"#Passager classes\nmax_p_class_n = X_train_data['Pclass'].max()\npclassS = [None] * (max_p_class_n)\n\nfor i in range(1 , max_p_class_n+1):\n    pclassS[i-1] = sum(np.logical_and(X_train_data['Pclass'] == i , X_train_data['Survived'] == 1))\n\npclassD = [None] * (max_p_class_n)\nfor i in range(1 , max_p_class_n+1):\n    pclassD[i-1] = sum(np.logical_and(X_train_data['Pclass'] == i , X_train_data['Survived'] == 0))\n    \n# width of the bars\nbarWidth = 0.3\n# Choose the height of the blue bars\n# bars1 = [10, 9, 2]\nbars1 = pclassS\n# Choose the height of the cyan bars\nbars2 = pclassD\n# # The x position of bars\nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\n# # Create blue bars\nplt.bar(r1, bars1, width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Survived')\n# # Create cyan bars\nplt.bar(r2, bars2, width = barWidth, color = 'cyan', edgecolor = 'black',  capsize=7, label='Deceased')\n# # general layout\nplt.xticks([r + barWidth for r in range(len(bars1))], ['1ª' , '2ª' ,'3ª'])\nplt.ylabel('Total')\nplt.xlabel('Class')\nplt.title(\"Class graph\")\n\nplt.legend()\n# # Show graphic\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:56.942856Z","iopub.execute_input":"2022-03-26T04:08:56.943185Z","iopub.status.idle":"2022-03-26T04:08:57.138823Z","shell.execute_reply.started":"2022-03-26T04:08:56.943145Z","shell.execute_reply":"2022-03-26T04:08:57.138139Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<h3> 2D) Cheking the SibSp (siblings / spouses aboard)</h3>","metadata":{}},{"cell_type":"code","source":"# X_train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nmax_parch_n = X_train_data['SibSp'].max()\nprint(max_parch_n)\n\npNS = [None] * max_parch_n\nfor i in range(0, max_parch_n):\n    pNS[i] = np.logical_and(X_train_data['SibSp'] == i , X_train_data['Survived'] == 1).astype(int)\n    pNS[i] = sum(pNS[i])\n# print(pNS)\npnD = [None] * max_parch_n\nfor i in range(0, max_parch_n):\n    pnD[i] = np.logical_and(X_train_data['SibSp'] == i , X_train_data['Survived'] == 0).astype(int)\n    pnD[i] = sum(pnD[i])\n# print(pnD)\n\na = torch.randn(10)\nb = a <= 0\nindices = b.nonzero()\n\n# width of the bars\nbarWidth = 0.3\n \n# Choose the height of the blue bars\n# bars1 = [10, 9, 2]\nbars1 = pNS\n# Choose the height of the cyan bars\nbars2 = pnD\n \n# The x position of bars\nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\n \n# Create blue bars\nplt.bar(r1, bars1, width = barWidth, color = 'blue', edgecolor = 'black', capsize=7, label='Survived')\n \n# Create cyan bars\nplt.bar(r2, bars2, width = barWidth, color = 'cyan', edgecolor = 'black',  capsize=7, label='Deceased')\n# general layout\nplt.xticks([r + barWidth for r in range(len(bars1))], ['Alone', '1', '2', '3', '4',  '5', '6' , '7'])\nplt.legend()\nplt.ylabel('Total')\nplt.xlabel('siblings / spouses aboard')\nplt.title(\"Company graph\")\n# Show graphic\nplt.show()\nmodSibSp = (X_train_data['SibSp'] >= 1)\n# print(modParctch.astype(int))\nX_train_data['SibSp'] = modSibSp.astype(int)\n#Saying that is like to say that all persons with 1+ is 50% 50% to survive","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:57.140104Z","iopub.execute_input":"2022-03-26T04:08:57.140504Z","iopub.status.idle":"2022-03-26T04:08:57.428872Z","shell.execute_reply.started":"2022-03-26T04:08:57.140466Z","shell.execute_reply":"2022-03-26T04:08:57.428204Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<h3> 2E) Cheking survivors by traveling alone or not </h3>","metadata":{}},{"cell_type":"code","source":"\n### NOT ALONE\n\noman = np.logical_and(X_train_data['SibSp'] == 0 , X_train_data['Parch'] == 0) \n\nsurvivedAlone = np.logical_and(oman , X_train_data['Survived'] == 0) \ndeceasedAlone = np.logical_and(oman , X_train_data['Survived'] == 1)\n\nprint('Survived Alone :' , sum(survivedAlone) ,'\\nDeceased Alone :' , sum(deceasedAlone))\n\n# print(sum(oman))\noman3 = np.logical_and(X_train_data['SibSp'] > 0 , X_train_data['Parch'] > 0) \n\n\nsurvivedNAlone = np.logical_and(oman3 , X_train_data['Survived'] == 0) \ndeceasedNAlone = np.logical_and(oman3 , X_train_data['Survived'] == 1)\n# oman2 = np.logical_and(oman2 , X_train_data['Survived'] == 0) \nprint('Suvived alone :' ,  sum(survivedNAlone), '\\nDeceased not alone',   sum(deceasedNAlone))\n\n\nX_train_data['Alone'] =  np.logical_and(X_train_data['SibSp'] == 0 , X_train_data['Parch'] == 0).astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:57.430334Z","iopub.execute_input":"2022-03-26T04:08:57.430819Z","iopub.status.idle":"2022-03-26T04:08:57.447632Z","shell.execute_reply.started":"2022-03-26T04:08:57.430780Z","shell.execute_reply":"2022-03-26T04:08:57.446029Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<h3> 2F) Checking the age </h3>","metadata":{}},{"cell_type":"code","source":"avarageAge = round(X_train_data['Age'].mean(),3)\nX_train_data['Age'] = X_train_data['Age'].replace(np.nan, avarageAge)\nprint(X_train_data['Age'])","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:57.448882Z","iopub.execute_input":"2022-03-26T04:08:57.449262Z","iopub.status.idle":"2022-03-26T04:08:57.459439Z","shell.execute_reply.started":"2022-03-26T04:08:57.449224Z","shell.execute_reply":"2022-03-26T04:08:57.458562Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<h1> 3. Correlation Matrix formation </h1>","metadata":{}},{"cell_type":"code","source":"#DATA ANALYZES\n# pd.options.mode.chained_assignment = None  # default='warn' Removing data warnings (: \n#Data treatment\n\nle = preprocessing.LabelEncoder()\nX_train_data['Ticket'] = le.fit_transform(X_train_data['Ticket'])\nX_train_data['Name'] = le.fit_transform(X_train_data['Name'])\nX_train_data['Sex'] = le.fit_transform(X_train_data['Sex'])\n# X_train_data['Sex2'] = X_train_data['Sex']**2 \nX_train_data['Cabin'] = le.fit_transform(X_train_data['Cabin'].astype(str))\nX_train_data['Embarked'] = le.fit_transform(X_train_data['Embarked'].astype(str))\n\nX_test['Ticket'] = le.fit_transform(X_test['Ticket'])\nX_test['Name'] = le.fit_transform(X_test['Name'])\nX_test['Sex'] = le.fit_transform(X_test['Sex'])\n# X_test['Sex2'] = X_test['Sex']**2\nX_test['Cabin'] = le.fit_transform(X_test['Cabin'].astype(str))\nX_test['Embarked'] = le.fit_transform(X_test['Embarked'].astype(str))\n\n# #Get info about the data\ncolumnsNamesArr = X_train_data.columns.values\nnumeric_col = columnsNamesArr\n \n# Correlation Matrix formation\ncorr_matrix = X_train_data.loc[:,numeric_col].corr()\nplt.figure(figsize = (16,5))\nsn.heatmap(corr_matrix, annot=True, linewidths=.9)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:57.460709Z","iopub.execute_input":"2022-03-26T04:08:57.461481Z","iopub.status.idle":"2022-03-26T04:08:58.613440Z","shell.execute_reply.started":"2022-03-26T04:08:57.461446Z","shell.execute_reply":"2022-03-26T04:08:58.609835Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"X_train_data","metadata":{}},{"cell_type":"markdown","source":"<h1> 4. Selecting the dataset features and split the rows </h1>","metadata":{}},{"cell_type":"code","source":"y_train_data = X_train_data['Survived']\n\ndropCollumns = ['Survived','PassengerId','Name', 'SibSp', 'Parch', 'Ticket']\ntry:\n    X_train_data.drop(dropCollumns,  axis=1, inplace=True)\nexcept:\n    print(\"Something went wrong on drop collumns\")\n    pass\n\nX_train, X_validation_set, y_train, y_validation_set = train_test_split(X_train_data, y_train_data, test_size=0.1 , random_state=1234)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_validation_set = sc.transform(X_validation_set)\n\n\n#Converting into a dataframe\nX_train_torch = torch.tensor(X_train.astype(np.float32))\nX_validation_set_torch = torch.tensor(X_validation_set.astype(np.float32))\ny_train_torch = torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1)\ny_validation_set_torch = torch.tensor(y_validation_set.values.astype(np.float32)).unsqueeze(1)\n\ninputDIm = X_train_torch.dim()\nprint(inputDIm)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:58.616009Z","iopub.execute_input":"2022-03-26T04:08:58.616462Z","iopub.status.idle":"2022-03-26T04:08:58.640843Z","shell.execute_reply.started":"2022-03-26T04:08:58.616422Z","shell.execute_reply":"2022-03-26T04:08:58.639973Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<h1> 5. Machine learning model</h1>","metadata":{}},{"cell_type":"code","source":"class linearRegression(nn.Module):\n    def __init__(self, inputDim, outputDim):\n        super(linearRegression, self).__init__()\n        self.linear = nn.Linear(inputDim, outputDim)\n\n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n\n##Hyperparams\ninputDim = X_train_torch.size(1) #Number of features\noutputDim = 1       # takes variable 'y'\nlearningRate = 0.01\nepochs = 3000\n##End of hyperparams\n\nmodel = linearRegression(inputDim, outputDim)\n##### For GPU #######\nif torch.cuda.is_available():\n    model.cuda()\n    \n\n# GRADIENT MODE AND LOSS FUNCTION  \ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=0.01)\n\nloss_values = []\n\n# 3) Training loop\nfor epoch in range(epochs):\n    # Forward pass and loss\n\n    y_pred = model(X_train_torch)\n    loss = criterion(y_pred, y_train_torch)\n\n    # Backward pass and update\n    loss.backward()\n    optimizer.step()\n\n    # zero grad before new step\n    optimizer.zero_grad()\n    loss_values.append(loss.item() / len(X_train_torch)) #Optimize this please\n\n    \n    loss_values.append(loss.item() / len(X_train_torch)) #Optimize this please\n    if (epoch+1) % 100 == 0:\n        print(loss.item())\n    #     print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n\n# Plot loss \nplt.plot(loss_values)\npyPred = pd.DataFrame(y_pred.detach().numpy())\nsizeY = len(pyPred[0])\ncorrects = 0\nmistakes = 0 \n\n#Correct X incorrect Predictions \npredicted = {}\n\nfor i in range(0, sizeY):\n    if(pyPred[0][i] >= 0.5):\n        predicted[i] = int(1)\n    else:\n        predicted[i] = int(0)\n        \n    if(y_train_torch[i] == predicted[i]):\n        corrects += 1\n    else: \n        mistakes += 1\nprint(corrects, mistakes)\n\n\n#Acuraccy\nwith torch.no_grad():\n    y_predicted = model(X_train_torch)\n    y_predicted_cls = y_predicted.round()\n    acc = y_predicted_cls.eq(y_train_torch).sum() / float(y_train_torch.shape[0])\n    print(f'accuracy: {acc.item():.4f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:08:58.642325Z","iopub.execute_input":"2022-03-26T04:08:58.642600Z","iopub.status.idle":"2022-03-26T04:09:01.843439Z","shell.execute_reply.started":"2022-03-26T04:08:58.642565Z","shell.execute_reply":"2022-03-26T04:09:01.842264Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<h1> 7. Checking accuracy on validation set </h1>","metadata":{}},{"cell_type":"code","source":"learningRate = 3\n\nwith torch.no_grad():\n    y_predicted = model(X_validation_set_torch)\n    y_predicted_cls = (y_predicted > 0.5)\n    \n    acc = y_predicted_cls.eq(y_validation_set_torch).sum() / float(y_validation_set_torch.shape[0])\n    print(f'accuracy: {acc.item():.4f}')\n    \ncorrects = 0\nmistakes = 0\npredicted = {}\nfor i in range(0, y_validation_set_torch.size(0)):\n    if(y_validation_set_torch[i] == y_predicted_cls[i]):\n        corrects += 1\n    else: \n        mistakes += 1\n        \nprint(\"Corrects: \",corrects,\"\\nMistakes:\", mistakes)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:09:01.844718Z","iopub.status.idle":"2022-03-26T04:09:01.845356Z","shell.execute_reply.started":"2022-03-26T04:09:01.845110Z","shell.execute_reply":"2022-03-26T04:09:01.845135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 8. Test Set </h1>","metadata":{}},{"cell_type":"code","source":"X_test_ori = pd.DataFrame(pd.read_csv(\"/kaggle/input/titanic/test.csv\"))\nX_test_t = X_test\n\n#Modifying Parch\nmodParctch = (X_test_t['Parch'] >= 1)\nX_test_t['Parch'] = modParctch.astype(int)\n\n#Modifying SibSp\nmodSibSp = (X_test_t['SibSp'] >= 1)\nX_test_t['SibSp'] = modSibSp.astype(int)\n\n#Creating Alone variable\nX_test_t['Alone'] =  np.logical_and(X_test_t['SibSp'] == 0 , X_test_t['Parch'] == 0).astype(int)\n\n#Modifying the age\navarageAge = round(X_test_t['Age'].mean(),3)\nX_test_t['Age'] = X_test_t['Age'].replace(np.nan, avarageAge)\n\n#Dropping the tables\ntry:\n    X_test_t.drop(dropCollumns[1:],  axis=1, inplace=True)\nexcept:\n    print(\"Something went wrong when dropping collumns\")\n    pass\n\n#Converting the sex to numerical variable\nX_test_t['Sex'] = le.fit_transform(X_test['Sex'])\n# X_test_t['Cabin'] = le.fit_transform(X_test['Cabin'].astype(str))\n\n#########THIS IS REALLY REAALLY IMPORTANT\n# Just normalize data gives me 15% of agorithim icrease :3 beaut\n# Normalizing the data\nsc = StandardScaler()\nX_test_t = sc.fit_transform(X_test_t)\n##########\n\nX_test_t = torch.tensor(X_test_t.astype(np.float32))\n\n    \ny_predicted_cls = {}\nwith torch.no_grad():\n    y_predicted = model(X_test_t)\n    #Predicting the data \n    for i in range(0, y_predicted.size(0)):\n        if(y_predicted[i] >= 0.5):\n            y_predicted_cls[i] = int(1)\n        else:\n            y_predicted_cls[i] = int(0)\n\n    \n#     acc = y_predicted_cls.eq(y_validation_set_torch).sum() / float(y_validation_set_torch.shape[0])\n#     print(f'accuracy: {acc.item():.4f}')\n# print(y_predicted_cls)\n\noutput = pd.DataFrame({'PassengerId': X_test_ori.PassengerId, 'Survived': y_predicted_cls})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:09:01.846704Z","iopub.status.idle":"2022-03-26T04:09:01.847379Z","shell.execute_reply.started":"2022-03-26T04:09:01.847116Z","shell.execute_reply":"2022-03-26T04:09:01.847143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Same algorithm the Randon Forest \nfrom sklearn.ensemble import RandomForestClassifier\ny = y_train\nRF = RandomForestClassifier()\nRF.fit(X_train, y)\n# Make a prediction\ny_predict = RF.predict(X_train)\n\n(y == y_predict).mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:09:01.848641Z","iopub.status.idle":"2022-03-26T04:09:01.849261Z","shell.execute_reply.started":"2022-03-26T04:09:01.849023Z","shell.execute_reply":"2022-03-26T04:09:01.849047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!DEBIAN_FRONTEND=noninteractive apt-get install --yes keyboard-configuration \n\n!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 sudo dpkg --purge\n!dpkg --install --yes cuda-repo-ubuntu*-9.0-local*.deb\n!sudo apt-get update\n!sudo apt-get install --yes cuda","metadata":{"execution":{"iopub.status.busy":"2022-03-26T04:09:01.850484Z","iopub.status.idle":"2022-03-26T04:09:01.851104Z","shell.execute_reply.started":"2022-03-26T04:09:01.850874Z","shell.execute_reply":"2022-03-26T04:09:01.850898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Aprendizados </h1>\n1. Modelamento de dados é realmente muito importante para melhorar o modelo que estou trabalhando.<br>\n2. Sempre SEMRPE normalize os inputs no treino e no teste. <br>\n3. Criar uma classe específica para limpar os dados (evitar reescrever código). <br>\n4. No próximo exercício começar visualizando o número de variáveis vazias no meu dataset. <br>\n5. CleanCode (;'. <br>\n6. Melhorar na criação de variáveis.","metadata":{}}]}